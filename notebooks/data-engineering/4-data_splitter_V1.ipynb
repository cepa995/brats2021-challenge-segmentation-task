{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting (Train/Val/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-16 18:38:27.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mbrain_tumor_segmentation.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /home/cepa995/workspace/brain-tumor-segmentation\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from brain_tumor_segmentation.config import PROCESSED_DATA_DIR\n",
    "\n",
    "# Define base directory\n",
    "base_dir = os.path.join(PROCESSED_DATA_DIR, \"training_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 1: 70/15/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping BraTS2021_UPENN-GBM_00157: Missing one or more image files\n",
      "⚠️ Skipping BraTS2021_UPENN-GBM_00170: Missing one or more image files\n",
      "⚠️ Skipping BraTS2021_UPENN-GBM_00186: Missing one or more image files\n",
      "⚠️ Skipping BraTS2021_UPENN-GBM_00337: Missing one or more image files\n",
      "⚠️ Skipping BraTS2021_UPENN-GBM_00414: Missing one or more image files\n",
      "⚠️ Skipping BraTS2021_UPENN-GBM_00834: Missing one or more image files\n",
      "⚠️ Skipping BraTS2021_UPENN-GBM_00839: Missing one or more image files\n",
      "Dataset split saved in dataset-split-strategies/dataset_splits_strategy-1_v1.json\n",
      "Total valid subjects used: 553 (out of 560)\n",
      "Train: 387, Validation: 83, Test: 83\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuration\n",
    "train_ratio = 0.7  # 70% Train\n",
    "val_ratio = 0.15   # 15% Validation\n",
    "test_ratio = 0.15  # 15% Test\n",
    "\n",
    "# List all subjects (directories)\n",
    "subjects = sorted([d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))])\n",
    "\n",
    "# Store only valid subjects (those with all required files)\n",
    "valid_subjects = []\n",
    "\n",
    "# Check for missing files\n",
    "for subject in subjects:\n",
    "    subject_path = os.path.join(base_dir, subject)\n",
    "\n",
    "    # Define expected image paths\n",
    "    t1ce = os.path.join(subject_path, f\"{subject}_t1wce.nii.gz\")\n",
    "    flair = os.path.join(subject_path, f\"{subject}_flair.nii.gz\")\n",
    "    label = os.path.join(subject_path, f\"{subject}_seg.nii.gz\")\n",
    "\n",
    "    # Ensure all required files exist\n",
    "    if all(os.path.exists(f) for f in [t1ce, flair, label]):\n",
    "        valid_subjects.append(subject)\n",
    "    else:\n",
    "        print(f\"⚠️ Skipping {subject}: Missing one or more image files\")\n",
    "\n",
    "# Check if we have enough subjects\n",
    "if len(valid_subjects) < 10:  # Arbitrary small number to ensure the split makes sense\n",
    "    raise ValueError(f\"Not enough valid subjects ({len(valid_subjects)}) to perform a meaningful split.\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Split dataset\n",
    "train_subjects, temp_subjects = train_test_split(valid_subjects, test_size=(val_ratio + test_ratio), random_state=42)  # 70% Train\n",
    "val_subjects, test_subjects = train_test_split(temp_subjects, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=42)  # 15% Val, 15% Test\n",
    "\n",
    "# Organize data in the correct format\n",
    "splits = {\n",
    "    \"train\": [],\n",
    "    \"validation\": [],\n",
    "    \"test\": []\n",
    "}\n",
    "\n",
    "# Function to format subject data\n",
    "def format_subject(subject):\n",
    "    subject_path = os.path.join(base_dir, subject)\n",
    "    return {\n",
    "        \"subject\": subject,\n",
    "        \"images\": [\n",
    "            os.path.join(subject_path, f\"{subject}_t1wce.nii.gz\"),\n",
    "            os.path.join(subject_path, f\"{subject}_flair.nii.gz\")\n",
    "        ],\n",
    "        \"label\": os.path.join(subject_path, f\"{subject}_seg.nii.gz\")\n",
    "    }\n",
    "\n",
    "# Store formatted data\n",
    "splits[\"train\"] = [format_subject(subj) for subj in train_subjects]\n",
    "splits[\"validation\"] = [format_subject(subj) for subj in val_subjects]\n",
    "splits[\"test\"] = [format_subject(subj) for subj in test_subjects]\n",
    "\n",
    "# Save split info\n",
    "output_file = \"dataset-split-strategies/dataset_splits_strategy-1_v1.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(splits, f, indent=4)\n",
    "\n",
    "print(f\"Dataset split saved in {output_file}\")\n",
    "print(f\"Total valid subjects used: {len(valid_subjects)} (out of {len(subjects)})\")\n",
    "print(f\"Train: {len(train_subjects)}, Validation: {len(val_subjects)}, Test: {len(test_subjects)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy 2: K-Fold Split (K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping BraTS2021_UPENN-GBM_00414: Missing one or more image files\n",
      "⚠️ Skipping BraTS2021_UPENN-GBM_00337: Missing one or more image files\n",
      "⚠️ Skipping BraTS2021_UPENN-GBM_00157: Missing one or more image files\n",
      "⚠️ Skipping BraTS2021_UPENN-GBM_00186: Missing one or more image files\n",
      "⚠️ Skipping BraTS2021_UPENN-GBM_00834: Missing one or more image files\n",
      "⚠️ Skipping BraTS2021_UPENN-GBM_00839: Missing one or more image files\n",
      "⚠️ Skipping BraTS2021_UPENN-GBM_00170: Missing one or more image files\n",
      "K-Fold cross-validation dataset saved in dataset-split-strategies/dataset_5-folds_strategy_2_v1.json\n",
      "Total valid subjects used: 553 (out of 560)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Configuration\n",
    "n_folds = 5  # Number of folds\n",
    "\n",
    "# List all subjects (directories)\n",
    "subjects = sorted([d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))])\n",
    "\n",
    "# Shuffle subjects for randomness\n",
    "random.seed(42)\n",
    "random.shuffle(subjects)\n",
    "\n",
    "# Initialize K-Fold\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Prepare dictionary to store folds\n",
    "cross_val_splits = {\"folds\": []}\n",
    "\n",
    "valid_subjects = []  # Store only subjects with all required files\n",
    "\n",
    "# Check for missing files before splitting\n",
    "for subject in subjects:\n",
    "    subject_path = os.path.join(base_dir, subject)\n",
    "\n",
    "    # Define expected image paths\n",
    "    t1 = os.path.join(subject_path, f\"{subject}_t1w.nii.gz\")\n",
    "    t1ce = os.path.join(subject_path, f\"{subject}_t1wce.nii.gz\")\n",
    "    t2 = os.path.join(subject_path, f\"{subject}_t2w.nii.gz\")\n",
    "    flair = os.path.join(subject_path, f\"{subject}_flair.nii.gz\")\n",
    "    label = os.path.join(subject_path, f\"{subject}_seg.nii.gz\")\n",
    "\n",
    "    # Ensure all required files exist\n",
    "    if all(os.path.exists(f) for f in [t1, t1ce, t2, flair, label]):\n",
    "        valid_subjects.append(subject)\n",
    "    else:\n",
    "        print(f\"⚠️ Skipping {subject}: Missing one or more image files\")\n",
    "\n",
    "# Check if we have enough valid subjects for K-Fold\n",
    "if len(valid_subjects) < n_folds:\n",
    "    raise ValueError(f\"Not enough valid subjects ({len(valid_subjects)}) to create {n_folds} folds.\")\n",
    "\n",
    "# Assign subjects to folds\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kf.split(valid_subjects)):\n",
    "    fold_data = {\n",
    "        \"fold\": fold_idx,\n",
    "        \"train\": [],\n",
    "        \"val\": []\n",
    "    }\n",
    "    \n",
    "    # Assign training subjects\n",
    "    for idx in train_idx:\n",
    "        subject = valid_subjects[idx]\n",
    "        subject_path = os.path.join(base_dir, subject)\n",
    "\n",
    "        # Image and label paths\n",
    "        t1 = os.path.join(subject_path, f\"{subject}_t1w.nii.gz\")\n",
    "        t1ce = os.path.join(subject_path, f\"{subject}_t1wce.nii.gz\")\n",
    "        t2 = os.path.join(subject_path, f\"{subject}_t2w.nii.gz\")\n",
    "        flair = os.path.join(subject_path, f\"{subject}_flair.nii.gz\")\n",
    "        label = os.path.join(subject_path, f\"{subject}_seg.nii.gz\")\n",
    "\n",
    "        fold_data[\"train\"].append({\n",
    "            \"subject\": subject,\n",
    "            \"images\": [t1, t1ce, t2, flair],\n",
    "            \"label\": label\n",
    "        })\n",
    "    \n",
    "    # Assign validation subjects\n",
    "    for idx in val_idx:\n",
    "        subject = valid_subjects[idx]\n",
    "        subject_path = os.path.join(base_dir, subject)\n",
    "\n",
    "        # Image and label paths\n",
    "        t1 = os.path.join(subject_path, f\"{subject}_t1w.nii.gz\")\n",
    "        t1ce = os.path.join(subject_path, f\"{subject}_t1wce.nii.gz\")\n",
    "        t2 = os.path.join(subject_path, f\"{subject}_t2w.nii.gz\")\n",
    "        flair = os.path.join(subject_path, f\"{subject}_flair.nii.gz\")\n",
    "        label = os.path.join(subject_path, f\"{subject}_seg.nii.gz\")\n",
    "\n",
    "        fold_data[\"val\"].append({\n",
    "            \"subject\": subject,\n",
    "            \"images\": [t1, t1ce, t2, flair],\n",
    "            \"label\": label\n",
    "        })\n",
    "\n",
    "    cross_val_splits[\"folds\"].append(fold_data)\n",
    "\n",
    "# Save splits to JSON\n",
    "output_file = f\"dataset-split-strategies/dataset_{n_folds}-folds_strategy_2_v1.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(cross_val_splits, f, indent=4)\n",
    "\n",
    "print(f\"K-Fold cross-validation dataset saved in {output_file}\")\n",
    "print(f\"Total valid subjects used: {len(valid_subjects)} (out of {len(subjects)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
